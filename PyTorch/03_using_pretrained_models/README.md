# 第3章：使用预训练模型

## 📖 章节概述

在实际应用中，从零开始训练神经网络往往需要大量数据和计算资源。**预训练模型**（Pretrained Models）提供了一个强大的起点——这些模型已经在大规模数据集上训练过，学习到了丰富的特征表示。

本章将介绍如何使用 PyTorch 的 `torchvision` 库加载和使用预训练模型，以及如何通过**迁移学习**将这些模型应用到你自己的问题上。

## 🎯 学习目标

完成本章学习后，你将能够：

1. 了解常用的预训练模型架构（ResNet、VGG、EfficientNet 等）
2. 加载预训练模型并进行推理
3. 理解迁移学习的原理和应用场景
4. 使用预训练模型进行特征提取
5. 微调预训练模型以适应新任务

## 📚 章节内容

| 节 | 文件 | 主题 | 预计时间 |
|---|------|------|---------|
| 3.1 | [01_torchvision_models.md](./01_torchvision_models.md) | torchvision 模型库 | 30 分钟 |
| 3.2 | [02_model_inference.md](./02_model_inference.md) | 模型推理 | 40 分钟 |
| 3.3 | [03_transfer_learning.md](./03_transfer_learning.md) | 迁移学习 | 50 分钟 |

## 💻 示例代码

所有可运行的示例代码位于 `examples/` 目录：

- [`image_classification.py`](./examples/image_classification.py) - 使用预训练模型进行图像分类
- [`feature_extraction.py`](./examples/feature_extraction.py) - 特征提取与迁移学习

## 🔬 物理视角：为什么预训练有效？

### 特征的层次性与普适性

预训练模型有效的原因与物理中的**普适性**（Universality）概念类似：

1. **低层特征是普适的**：
   - 图像的边缘、纹理、颜色等低层特征在不同任务中是通用的
   - 类似于物理中，基本的对称性和守恒律在不同系统中都适用

2. **层次化表示**：
   - 神经网络逐层提取从简单到复杂的特征
   - 类似于重整化群，每一层在不同尺度上描述系统

3. **迁移学习**：
   - 将在一个任务上学到的知识迁移到另一个任务
   - 类似于物理中用已知系统的解去理解新系统

### 迁移学习的物理类比

| 机器学习 | 物理类比 |
|---------|---------|
| 预训练模型 | 已知系统的精确解 |
| 微调 | 微扰论 |
| 特征提取 | 基函数展开 |
| 冻结层 | 固定自由度 |

## 📋 前置要求

- 完成第1-2章的学习
- 了解卷积神经网络的基本概念（本章会简要介绍）
- 建议有 GPU（CPU 也可以运行，但较慢）

## 🚀 快速开始

```bash
# 确保安装了 torchvision
pip install torchvision

# 运行示例
cd 03_using_pretrained_models/examples
python image_classification.py
python feature_extraction.py
```

## 📦 常用预训练模型一览

| 模型系列 | 特点 | 参数量 | 适用场景 |
|---------|------|--------|---------|
| ResNet | 残差连接，易训练 | 11M-60M | 通用分类 |
| VGG | 简单堆叠，易理解 | 138M | 教学、特征提取 |
| EfficientNet | 高效，精度高 | 5M-66M | 资源受限场景 |
| ViT | Transformer架构 | 86M-632M | 大数据集 |
| ConvNeXt | 现代CNN | 29M-350M | 通用分类 |

## ⏭️ 下一章预告

掌握了如何使用预训练模型后，第4章将介绍如何从零开始构建自定义的神经网络架构。

---

*预计总学习时间：约 2 小时*

